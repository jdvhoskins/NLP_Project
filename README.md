# Free-Form Sentence Generation For Natural Language Processing

This project was written for a natural language processing class (CAP-6640) at the University of Central Florida. It explored the use of conditional probabilities in generating free-form sentences. My partner on this project was Jagrutee Paladne, and all work was a joint effort between us. The data set used for this project is the Manually Annotated Sub-Corpus (MASC) of the Open American National Corpus. While every word and phrase in the MASC has been fully tagged, the accuracy and consistency of the source text is left unaltered. This required a number of corrections to the corpus which were made manually. The edits made to the corpus included accounting for dialects ([fightn’] → [fighting]), using context to clarify what unknown characters ought to be ([I] [?ll] [be] [back] → [I] ['ll] [be] [back]), removal of tokens that would likely cause confusion (tokens like [example@somewhere.com]), and normalizing the character encoding for numerous symbols. An example of the last set of changes would be setting the quotation marks in both the tags and the tokens to U+0022 (neutral quote). Originally, the corpus contained quotation marks as a mix of U+0022, U+201C (left quote), U+201D (right quote), and doubles of both directed and neutral single quotes (left = U+2018, right = U+0029, neutral = U+0027 ). The cleaned up corpus is contained in corpus_clean.tar, which will need to be uncompressed and located in the project directory. The Natural Language Toolkit (NLTK) in Python was used for parsing the corpus, and for creating both the n-grams and the probability distributions.

# Corpus Statistics

| Property | Quantity |
| :-:      | :-:      |
| Tokens   | 517,943  |
| Unique Tokens | 27,075 |
| Unique Tokens Starting with a Letter | 25,116 |
| Unique Tags | 44 |

# Abstract

Individual, unrelated sentences were generated using probability distributions based on either n-grams or part-of-speech (POS) tags. The three n-gram models used Bayesian statistics stemming from either bigrams, trigrams, or four-grams. The POS model utilized Bayesian statistics for tag-tag bigrams, as well as the word distributions for each POS tag. The sentences generated by these models were assessed primarily on clarity of the sentence meaning. Most sentences contained numerous grammatical errors, and lacked any proper sentence structure. The best models for this project were based on the trigrams and four-grams in the corpus.

# Linguistic Model Implementation

The two classes of models studied for this project both used Markov chains of varying lengths and naive-Bayes statistics to generate an English sentence one word at a time. When parsing the corpus, a special token was added following each sentence. This token consisted of an end-of-sentence tag (EOS) and an empty string ("") as the word. Whenever a model generated this token, the sentence was terminated. The table below illustrates the terminology used for these models.

| Term | Examples|
| :-:  | :-:     |
| Bigram | IN THE,  THE UNITED,  UNITED STATES |
| Trigram | IN THE UNITED,  THE UNITED STATES,  UNITED STATES DISTRICT |
| four-gram | IN THE UNITED STATES,  THE UNITED STATES DISTRICT,  UNITED STATES DISTRICT COURT |
| POS tag | VBD (verb - past tense), EOS (end of sentence), NNP (proper noun - singular) |

# N-gram models

The basis of the n-gram models is a Markov chain of an order that is 2 less than the size of the n-gram used. That is, the chain has a memory of 0 for bigrams, 1 for trigrams, and 2 for four-grams. The penultimate word in the n-gram represents the current state of the system while the last word of the n-gram is what is being predicted. In the case that a particular n-gram can not be used (eg. when generating the first word or two for trigrams and four-grams), the next smaller n-gram is used instead. This reduction is applied recursively until a valid sized n-gram is reached. The order of the words in the corpus is the only factor considered by the n-gram models. No information regarding the part of speech, the lemma, synsets, or any other factor is utilized. 

# Part-of-speech model

The POS model is a factored language model where the POS tag of the next word is determined using a Markov chain of order 0. With a memory of 0, only the tag of the current word is used to predict the tag of the next word in the sentence. Once the next tag is determined a random word having that tag is selected based on the word distribution for that tag. Similar to the n-gram models, the POS model has no knowledge of lemmas, synsets, or any other factors. 


# Sentence Generation

To create the sentences for each model, words were generated according to the model’s rules until the empty string was generated. Originally, the sentences were to be generated from randomly selected words from the corpus that would act as seeds. To be more consistent with Barros and Lloret, whose work this project was modeled after [1], the seeds words were changed to the empty string. Thirty candidate sentences were generated, whereupon the candidate sentence with the highest weighted probability was kept. This generation process was repeated until 50 sentences had been saved for each model.

Note that because the sentence probability is multiplicative, one and two word sentences were consistently the "best" despite their lack of content. To prevent these sentences from dominating the results, the sentence probability was weighted by the sentence length. This favored longer sentences which actually had enough content to actually be evaluated. For readability, the probabilities listes are actually the natural log of the probabilities, so less negative is better.

# Evaluation

The final set of 200 sentences (50 each for bigrams, trigrams, four-grams, and POS tags) can be found in Project_output.txt. Each sentence was manually evaluated and categorized as either "Makes Sense", "Makes Some Sense", or "Makes No Sense". Grammatical and/or punctuation errors were ignored for this evaluation, and only the clarity of the underlying idea was considered. The table below summarizes the sentence ratings for the four models used. While all of the models had at least 10 sentences rated as "Makes Sense", the numbers for the bigram model and the POS model could be seen as artificially high. Of the 18 such sentences for bigrams, 11 were single words like, "yeah." and "no.", while for the POS tag model all 10 of them were single word sentences. 


| | Makes Sense | Makes some sense | Makes no sense |
| :-: | :-: | :-: | :-: |
| Bigrams | 18 | 11 | 21 |
| Trigrams | 14 | 21 | 15 |
| Four-grams | 15 | 26 | 9 |
| POS Tags | 10 | 14 | 26 |

# Conclusions

It is clear that the trigram and four-gram models performed better than the bigram and POS-tag models, despite still being unreliable in terms of generating useful sentences. Using only the current token to determine the next one is simply insufficient for free form sentence generation. Using a template or a grammar could greatly improve the performance of all of the models, but markedly so for the bigram and POS-tag models. Other methods for improving on these results include using categorical information (lemmas), refining the corpus to remove some of the spurious tokens, and training with a larger corpus. Also, for the POS-tag model, better performance could be obtained by simply increasing the order of the Markov chain used for the tag prediction. The improvement would likely be similar to that seen when comparing the bigram and trigram models.

[1]	C. Barros and E. Lloret, "Analysing the influence of semantic knowledge in natural language generation," 2017 Twelfth International Conference on Digital Information Management (ICDIM), Fukuoka, 2017, pp. 185-190.
